# Spam Email Detector

## Overview

This project is a Python-based spam email detector that uses machine learning to classify email messages as either "spam" or "ham" (not spam). It's built using scikit-learn for the machine learning model, NLTK for text processing, and Streamlit for creating a user-friendly web application.

## Features

* **Spam/Ham Classification:** Accurately classifies email messages as spam or ham.
* **Text Preprocessing:** Includes text cleaning steps such as:
    * Lowercasing
    * Removing URLs
    * Removing punctuation
    * Removing extra spaces
    * Removing single characters
    * Removing stop words
* **Feature Extraction:** Uses TF-IDF (Term Frequency-Inverse Document Frequency) to convert text into numerical features.
* **Machine Learning Model:** Employs a Random Forest Classifier for classification.
* **Web Interface:** A simple and intuitive web interface built with Streamlit allows users to input email messages and get predictions.

## Technical Details

* **Programming Language:** Python
* **Libraries:**
    * scikit-learn (sklearn)
    * pandas
    * NLTK (Natural Language Toolkit)
    * Streamlit
    * pickle
    * re (Regular expressions)
    * string
    * imblearn (for handling class imbalance)
* **Model:** Random Forest Classifier
* **Vectorization:** TF-IDF
* **Data Balancing: ** Random Oversampling
* **File Storage:** Pickle files are used to save the trained model, vectorizer, and label encoder.

## Project Structure

The project consists of the following main files:

* `spam.csv`: The dataset containing email messages and their labels (spam/ham).
* `app.py`: The Streamlit application script that provides the user interface and uses the trained model for predictions.
* `spam_detector_random_forest.pkl`:  Pickle file containing the trained Random Forest model.
* `tfidf_vectorizer.pkl`: Pickle file containing the fitted TF-IDF vectorizer.
* `label_encoder.pkl`: Pickle file containing the fitted LabelEncoder.
* `requirements.txt`: (Optional) A list of Python dependencies for the project.

## Setup Instructions

1.  **Clone the Repository:** (If applicable)
    ```bash
    git clone <your_repository_url>
    cd spam-email-detector
    ```

2.  **Create a Virtual Environment (Recommended):**
    ```bash
    conda create -n spam_detector_env python=3.x # Or python=3.9, etc.
    conda activate spam_detector_env
    ```

3.  **Install Dependencies:**
    ```bash
    pip install -r requirements.txt  #If you have a requirements.txt
    ```
    If you don't have a requirements.txt, install the libraries individually
    ```bash
    conda install pandas scikit-learn nltk streamlit
    pip install imbalanced-learn #install via pip
    ```

4.  **Download NLTK Stopwords (First time only):**
    Run the following commands in a Python interpreter:
    ```python
    import nltk
    nltk.download('stopwords')
    ```

5.  **Place Data and Model Files:**
    * Ensure that the `spam.csv`, `spam_detector_random_forest.pkl`, `tfidf_vectorizer.pkl`, and `label_encoder.pkl` files are in the same directory as the `app.py` script.

## How to Run the Application

1.  **Open your terminal or command prompt.**
2.  **Navigate to the directory containing the `app.py` file.**
    ```bash
    cd <path_to_your_project_directory>
    ```
3.  **Run the Streamlit application:**
    ```bash
    streamlit run app.py
    ```
4.  The application will open in your web browser.

## Usage

1.  **Enter Email Message:** In the text area, type or paste the email message you want to check for spam.
2.  **Click "Predict":** Click the "Predict" button to get the classification.
3.  **View Results:** The application will display whether the message is classified as "spam" or "ham."

##  Important Notes

* **File Locations:** The application expects the model files (`.pkl` files) to be in the same directory as the `app.py` script.  If you encounter errors, double-check the file paths.
* **Dependencies:** Ensure that all required Python libraries are installed.  Using a virtual environment is highly recommended to avoid conflicts with other projects.
* **Model Accuracy:** The accuracy of the spam detection depends on the quality and representativeness of the training data.  The provided model is a starting point and can be improved with more data and further tuning.
* **NLTK Stopwords:** The application requires the NLTK stopwords corpus.  The `nltk.download('stopwords')` command ensures that these are downloaded.  This is usually a one-time operation.
* **Pickle Security Warning:** Be cautious when loading pickle files from untrusted sources, as they can potentially execute arbitrary code.  In this project, the pickle files are assumed to be generated by trusted code.
* **Reproducibility:** This project uses `random_state` in several places (e.g., `train_test_split`, `RandomOverSampler`, and the Random Forest model) to ensure consistent results across multiple runs.

##  Potential Improvements

* **Model Improvement:** Experiment with different machine learning models or hyperparameter tuning to improve accuracy.
* **Feature Engineering:** Explore additional features, such as email headers, sender information, or the presence of specific keywords or URLs.
* **Data Augmentation:** Gather a larger and more diverse dataset to improve the model's generalization ability.
* **Enhanced UI:** Enhance the Streamlit application with a more user-friendly interface, such as the ability to upload email files or display prediction probabilities.
* **Deployment:** Deploy the application to a cloud platform to make it accessible to a wider audience.
* **Logging:** Implement logging to track application usage and potential errors.
* **Error Handling:** Add more robust error handling.


##  Author
Shouryam Sankritya
